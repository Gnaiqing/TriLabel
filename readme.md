## TriLabel: Cleansing Weak Supervision Label Noise with Active Learning

TriLabel is a human-in-the-loop framework that leverages active learning to cleanse label noise generated by programmatic weak supervision framework. It can also evaluate the quality of generated dataset and control data quality to satisfy user-provided constraints.

## Installation

First, install the WRENCH benchmark for datasets and label model:

```
pip install ws-benchmark==1.1.2rc0
pip install pytokenizations==0.7.2 pgmpy llvmlite==0.32.1 numba==0.49.1
pip uninstall networkx
pip install networkx==2.3
```

Then install other required packages for TriLabel:

```
pip install pytorch-lightning
pip install matplotlib
```

## Running

For running the framework on a single dataset, run

`python trilabel.py --dataset [dataset_name] --sample_budget [N] --sample_per_iter [b]`

This command sampling b data points for labelling at each batch and sample N data points in total. After each batch is sampled, an active learning model is trained on sampled points and used to revise PWS labels. 

TriLabel also supports the user to specify desired label accuracy and/or coverage. For example, the command below set desired label accuracy to be 90% and maximize label coverage under this constraints:

`python trilabel.py --dataset youtube --desired_label_acc 0.9 --optimize_target coverage `

Commonly used arguments include:

```Â 
--dataset [dataset_name:str]  # specify dataset name
--sample_budget [N:int]  # specify total sample budget
--sample_budget_per_iter [b:int]  # batch size for sampling
--sampler [sampler_name:str]  # active sampler
--desired_label_acc [acc:float] # specify the desired label accuracy
--desired_label_cov [cov:float] # specify the desired label coverage
--optimize_target [target:str] # specify the target for optimization (one of "accuracy", "coverage", "f1")
--repeats [r:int]  # repeat the experiment multiple times using different seeds
--evaluate # optional,evaluate the label quality using golden labels
```













